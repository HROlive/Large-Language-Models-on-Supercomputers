{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa76d21e-5f67-4405-8de3-048673db1b71",
   "metadata": {},
   "source": [
    "# ZeRO with Deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059562e5-77a2-48e1-a7f2-5861fcc7bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./examples/deepspeed_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./examples/deepspeed_example.py\n",
    "\n",
    "# Import necessary libraries\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import deepspeed\n",
    "\n",
    "# Initialize Accelerate\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"train[:2000]\")  # Using a small subset for demonstration\n",
    "eval_dataset = load_dataset(\"imdb\", split=\"test[2000:2500]\")  # Subset for quick evaluation\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Define training arguments with DeepSpeed config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=80, # Match DeepSpeed config\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=0.00015,  # Match DeepSpeed config\n",
    "    weight_decay=0.01,  # Match DeepSpeed config\n",
    "    fp16=True,  # Match DeepSpeed config\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset\n",
    ")\n",
    "\n",
    "# Prepare model and data with Accelerate\n",
    "model, tokenized_dataset = accelerator.prepare(model, tokenized_dataset)\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd351b8-bf34-4adc-a0f6-98c5bdd625f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tooling/config/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tooling/config/ds_config.json\n",
    "{ \n",
    "  \"fp16\": {\n",
    "    \"enabled\": true,\n",
    "    \"loss_scale\": 0,\n",
    "    \"loss_scale_window\": 1000,\n",
    "    \"hysteresis\": 2,\n",
    "    \"min_loss_scale\": 1\n",
    "  },\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"AdamW\",\n",
    "    \"params\": {\n",
    "      \"lr\": 0.00015,\n",
    "      \"betas\": [0.9, 0.999],\n",
    "      \"eps\": 1e-8,\n",
    "      \"weight_decay\": 0.01\n",
    "    }\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": 2,\n",
    "    \"offload_optimizer\": {\n",
    "      \"device\": \"none\",\n",
    "      \"pin_memory\": true\n",
    "    },\n",
    "    \"contiguous_gradients\": true,\n",
    "    \"overlap_comm\": true,\n",
    "    \"allgather_partitions\": true,\n",
    "    \"reduce_scatter\": true,\n",
    "    \"reduce_bucket_size\": 200000000,\n",
    "    \"allgather_bucket_size\": 200000000\n",
    "  },\n",
    "  \"steps_per_print\": 100,\n",
    "  \"train_batch_size\": 320,\n",
    "  \"train_micro_batch_size_per_gpu\": 80,\n",
    "  \"gradient_accumulation_steps\": 1,\n",
    "  \"wall_clock_breakdown\": false\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ee8061-096b-4a95-9a1b-4ede664c77f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tooling/config/accelerate_ds_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tooling/config/accelerate_ds_config.yaml\n",
    "compute_environment: LOCAL_MACHINE\n",
    "debug: false\n",
    "distributed_type: DEEPSPEED\n",
    "deepspeed_config:\n",
    "  deepspeed_config_file: \"/home/fs71550/simeon/LLMs-on-supercomputers/tooling/config/ds_config.json\"\n",
    "  deepspeed_multinode_launcher: standard\n",
    "  zero3_init_flag: false\n",
    "downcast_bf16: 'yes'\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "num_machines: 2\n",
    "num_processes: 4\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "use_cpu: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cdaa92-0a89-46fc-9f99-fed07f005d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./tooling/slurm_scripts/ds_example.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tooling/slurm_scripts/ds_example.sh\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=training_example\n",
    "#SBATCH --account=p71550\n",
    "##SBATCH --account=p70824 # training account, please uncomment for training\n",
    "#SBATCH --nodes=2                    # Number of nodes\n",
    "#SBATCH --ntasks-per-node=1          # Number of tasks per node\n",
    "#SBATCH --cpus-per-task=256          # Number of CPU cores per task (including hyperthreading if needed)\n",
    "#SBATCH --partition=zen3_0512_a100x2\n",
    "#SBATCH --qos=admin\n",
    "##SBATCH --qos=zen3_0512_a100x2 # qos for training\n",
    "#SBATCH --gres=gpu:2                 # Number of GPUs per node\n",
    "#SBATCH --output=../../output/%x-%j.out  # Output file\n",
    "##SBATCH --reservation=\n",
    "\n",
    "######################\n",
    "### Set Environment ###\n",
    "######################\n",
    "module load miniconda3\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "source /opt/sw/jupyterhub/envs/conda/vsc5/jupyterhub-huggingface-v2/modules  # Activate the conda environment\n",
    "\n",
    "######################\n",
    "#### Set Network #####\n",
    "######################\n",
    "# Get the IP address of the master node (head node)\n",
    "nodes=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\")\n",
    "nodes_array=($nodes)\n",
    "node_0=${nodes_array[0]}\n",
    "\n",
    "NUM_PROCESSES=$(( SLURM_NNODES * SLURM_GPUS_ON_NODE ))\n",
    "\n",
    "export MASTER_ADDR=$node_0\n",
    "export MASTER_PORT=29500\n",
    "\n",
    "######################\n",
    "#### Prepare Launch ###\n",
    "######################\n",
    "# Configure Accelerate launch command\n",
    "\n",
    "export LAUNCHER=\"accelerate launch \\\n",
    "    --config_file \"../config/accelerate_ds_config.yaml\" \\\n",
    "    --machine_rank \\$SLURM_PROCID \\\n",
    "    --main_process_ip $MASTER_ADDR \\\n",
    "    --main_process_port $MASTER_PORT \\\n",
    "    --num_processes $NUM_PROCESSES \\\n",
    "    --num_machines $SLURM_NNODES \\\n",
    "    \"\n",
    "export PROGRAM=\"../../examples/deepspeed_example.py\"\n",
    "\n",
    "START=$(date +%s.%N)\n",
    "echo \"START TIME: $(date)\"\n",
    "\n",
    "export SRUN_ARGS=\"--cpus-per-task $SLURM_CPUS_PER_TASK --jobid $SLURM_JOBID\"\n",
    "export OMP_NUM_THREADS=256\n",
    "export CMD=\"$LAUNCHER $PROGRAM\"\n",
    "\n",
    "# Execute the command with srun to run on multiple nodes\n",
    "srun $SRUN_ARGS ../start_train.sh \"$CMD\"\n",
    "\n",
    "echo \"END TIME: $(date)\"\n",
    "END=$(date +%s.%N)\n",
    "RUNTIME=$(echo \"$END - $START\" | bc -l)\n",
    "echo \"Runtime: $RUNTIME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8aaf91-b211-464f-94f4-21418089803a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
